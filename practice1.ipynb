{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OlTaYqZ2rrm"
      },
      "source": [
        "# 5. **Torch를 활용한 자연어처리**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7URa7s_RBcHx",
        "outputId": "b6efe732-e58c-457e-a622-f6ddb996a32c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torchtext==0.14.0\n",
            "  Downloading torchtext-0.14.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.0) (4.66.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.0) (2.31.0)\n",
            "Collecting torch==1.13.0 (from torchtext==0.14.0)\n",
            "  Downloading torch-1.13.0-cp310-cp310-manylinux1_x86_64.whl (890.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m890.1/890.1 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchtext==0.14.0) (1.25.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchtext==0.14.0) (4.11.0)\n",
            "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==1.13.0->torchtext==0.14.0)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch==1.13.0->torchtext==0.14.0)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch==1.13.0->torchtext==0.14.0)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==1.13.0->torchtext==0.14.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m66.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext==0.14.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchtext==0.14.0) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.14.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.14.0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.14.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchtext==0.14.0) (2024.2.2)\n",
            "Installing collected packages: nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, nvidia-cudnn-cu11, torch, torchtext\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.2.1+cu121\n",
            "    Uninstalling torch-2.2.1+cu121:\n",
            "      Successfully uninstalled torch-2.2.1+cu121\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.17.1\n",
            "    Uninstalling torchtext-0.17.1:\n",
            "      Successfully uninstalled torchtext-0.17.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\n",
            "torchdata 0.7.1 requires torch>=2, but you have torch 1.13.0 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 1.13.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 torch-1.13.0 torchtext-0.14.0\n",
            "Collecting torchdata==0.5.0\n",
            "  Downloading torchdata-0.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.0) (2.0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.0) (2.31.0)\n",
            "Collecting portalocker>=2.0.0 (from torchdata==0.5.0)\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.5.0) (1.13.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchdata==0.5.0) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchdata==0.5.0) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchdata==0.5.0) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchdata==0.5.0) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.0->torchdata==0.5.0) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchdata==0.5.0) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.0->torchdata==0.5.0) (0.43.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.0) (3.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchdata==0.5.0) (2024.2.2)\n",
            "Installing collected packages: portalocker, torchdata\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.7.1\n",
            "    Uninstalling torchdata-0.7.1:\n",
            "      Successfully uninstalled torchdata-0.7.1\n",
            "Successfully installed portalocker-2.8.2 torchdata-0.5.0\n",
            "Collecting torch==1.13.1\n",
            "  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (4.11.0)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (8.5.0.96)\n",
            "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.10.3.66)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /usr/local/lib/python3.10/dist-packages (from torch==1.13.1) (11.7.99)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (67.7.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.10/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch==1.13.1) (0.43.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.13.0\n",
            "    Uninstalling torch-1.13.0:\n",
            "      Successfully uninstalled torch-1.13.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchaudio 2.2.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.5.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.14.0 requires torch==1.13.0, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.17.1+cu121 requires torch==2.2.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed torch-1.13.1\n"
          ]
        }
      ],
      "source": [
        "!pip install torchtext==0.14.0\n",
        "!pip install torchdata==0.5.0\n",
        "!pip install torch==1.13.1\n",
        "# 코드 실행 이후 Restart_runtime 해주시면 되겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H4lVi253ByX1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torch.optim as optim\n",
        "from torchtext.datasets import MNLI\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torch.utils.data import DataLoader, Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjNkey2SByZe",
        "outputId": "904ef2cb-4133-434f-df49-69022290e1ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "label:      1\n",
            "premise:    Conceptually cream skimming has two basic dimensions - product and geography.\n",
            "hypothesis: Product and geography are what make cream skimming work. \n"
          ]
        }
      ],
      "source": [
        "# 데이터 생성 및 확인\n",
        "train_list = list(MNLI(split='train'))\n",
        "test_list = list(MNLI(split='dev_matched'))\n",
        "\n",
        "# 0: entailment, 1: neutral, 2: contradiction\n",
        "tmp = train_list[0]\n",
        "print(f\"label:      {tmp[0]}\")\n",
        "print(f\"premise:    {tmp[1]}\")\n",
        "print(f\"hypothesis: {tmp[2]}\")\n",
        "\n",
        "# premise, hypothesis를 입력으로 해서 label을 맞추는 작업"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "A8s3rJwJBybR"
      },
      "outputs": [],
      "source": [
        "def prepare_data():\n",
        "    train_list = list(MNLI(split='train'))\n",
        "    test_list = list(MNLI(split='dev_matched'))\n",
        "    tokenizer = get_tokenizer('basic_english')\n",
        "\n",
        "    # Build Vocabulary\n",
        "    def yield_tokens(data_iter):\n",
        "        for _, premise, hypothesis in data_iter:\n",
        "            yield tokenizer(premise)\n",
        "            yield tokenizer(hypothesis)\n",
        "\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(iter(train_list)), specials=[\"<unk>\", \" <sep> \"])\n",
        "    vocab.set_default_index(vocab[\"<unk>\"])\n",
        "\n",
        "    return train_list, test_list, vocab, tokenizer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mv-B5wc-FbfW",
        "outputId": "67803f9c-f762-4862-e791-a3a2cbd16ab5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[108, 14, 39, 444]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# vocab의 역할: 텍스트를 정수입력 형태로 변환\n",
        "vocab(['here', 'is', 'an', 'example'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pGUVwihEJv8D"
      },
      "source": [
        "### **모델 정의하기 (예시)**\n",
        "모델은 `nn.EmbeddingBag` 레이어와 분류(classification) 목적을 위한 선형 레이어로 구성됩니다.\n",
        "\n",
        "기본 모드가 “평균(mean)”인 nn.EmbeddingBag 은 임베딩들의 “가방(bag)”의 평균 값을 계산합니다. 이때 텍스트(text) 항목들은 각기 그 길이가 다를 수 있지만, nn.EmbeddingBag 모듈은 *텍스트의 길이를 오프셋(offset)으로 저장하고 있으므로 패딩(padding)이 필요하지는 않습니다.*\n",
        "\n",
        "\n",
        "![모델](https://tutorials.pytorch.kr/_images/text_sentiment_ngrams_model.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "86-WJrAA7I4G"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "\n",
        "class MNLIDataset(Dataset):\n",
        "    def __init__(self, data_list, vocab, tokenizer):\n",
        "        self.data = data_list\n",
        "        self.vocab = vocab\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        label, premise, hypothesis = self.data[idx]\n",
        "        inputs = premise + ' ' + hypothesis\n",
        "        inputs = self.vocab(self.tokenizer(inputs))\n",
        "        return torch.tensor(inputs, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "def collate_batch(batch):\n",
        "    label_list, text_list = [], []\n",
        "    for _text, _label in batch:\n",
        "        text_list.append(_text)\n",
        "        label_list.append(_label)\n",
        "    text_list = pad_sequence(text_list, batch_first=True, padding_value=0)\n",
        "    label_list = torch.tensor(label_list, dtype=torch.long)\n",
        "    return text_list, label_list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9bDZ3vGsFbg7"
      },
      "outputs": [],
      "source": [
        "class TextClassificationModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class=3):\n",
        "        super(TextClassificationModel, self).__init__()\n",
        "        self.embedding = nn.EmbeddingBag(vocab_size, embed_dim, sparse=False)\n",
        "        self.fc1 = nn.Linear(embed_dim, embed_dim * 4)\n",
        "        self.fc2 = nn.Linear(embed_dim * 4, embed_dim * 2)\n",
        "        self.dropout = nn.Dropout(0.5)  # Dropout layer\n",
        "        self.fc3 = nn.Linear(embed_dim * 2, num_class)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.5\n",
        "        self.embedding.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc1.bias.data.zero_()\n",
        "        self.fc2.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc2.bias.data.zero_()\n",
        "        self.fc3.weight.data.uniform_(-initrange, initrange)\n",
        "        self.fc3.bias.data.zero_()\n",
        "\n",
        "    def forward(self, text):\n",
        "        embedded = self.embedding(text)\n",
        "        embedded = self.fc1(embedded)\n",
        "        embedded = self.dropout(embedded)  # Dropout\n",
        "        embedded = self.fc2(embedded)\n",
        "        output = self.fc3(embedded)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqoKWjvJSOi1"
      },
      "source": [
        "### **학습 정의**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpJXec-UJrwa",
        "outputId": "7876df01-08d2-40c8-b4dd-d4bd90e3bbcd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Loss: 1.1252681176667496\n",
            "Epoch 2, Loss: 1.0693405511238974\n",
            "Epoch 3, Loss: 1.0613488348630757\n",
            "Epoch 4, Loss: 1.0561046474643605\n",
            "Epoch 5, Loss: 1.0525861101800569\n",
            "Epoch 6, Loss: 1.0494393051117463\n",
            "Epoch 7, Loss: 1.0465786848970078\n",
            "Epoch 8, Loss: 1.0445157542309906\n",
            "Epoch 9, Loss: 1.0424967128176343\n",
            "Epoch 10, Loss: 1.0407595814993749\n",
            "Final Accuracy: 47.56%\n"
          ]
        }
      ],
      "source": [
        "train_data, test_data, vocab, tokenizer = prepare_data()\n",
        "train_dataset = MNLIDataset(train_data, vocab, tokenizer)\n",
        "test_dataset = MNLIDataset(test_data, vocab, tokenizer)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_batch)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_batch)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = TextClassificationModel(len(vocab), 64, num_class=3).to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.95)\n",
        "\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "    scheduler.step()\n",
        "    print(f'Epoch {epoch+1}, Loss: {total_loss/len(train_loader)}')\n",
        "\n",
        "\n",
        "model.eval()\n",
        "total_acc, total_count = 0, 0\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in test_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        total_acc += (outputs.argmax(1) == labels).sum().item()\n",
        "        total_count += labels.size(0)\n",
        "\n",
        "print(f\"Final Accuracy: {total_acc/total_count * 100:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTstDaM9SRZ9"
      },
      "source": [
        "### **학습된 모델 평가**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlZcslYBHWwy",
        "outputId": "e547c8a6-f0fb-4191-c36f-7a2fff0ea934"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "평가 진행중.. [1000/9815]\n",
            "평가 진행중.. [2000/9815]\n",
            "평가 진행중.. [3000/9815]\n",
            "평가 진행중.. [4000/9815]\n",
            "평가 진행중.. [5000/9815]\n",
            "평가 진행중.. [6000/9815]\n",
            "평가 진행중.. [7000/9815]\n",
            "평가 진행중.. [8000/9815]\n",
            "평가 진행중.. [9000/9815]\n",
            "학습된 모델의 최종 정확도: 47.397 %\n"
          ]
        }
      ],
      "source": [
        "total_acc, total_count = 0, 0\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  # gpu가속을 위함\n",
        "model = model.to(device)\n",
        "\n",
        "for i, data in enumerate(test_list):\n",
        "    # 데이터 호출\n",
        "    label = data[0]\n",
        "    premise = data[1]\n",
        "    hypothesis = data[2]\n",
        "\n",
        "    # Forward pass\n",
        "    inputs = premise + ' ' + hypothesis  # premise와 hypothesis를 모두 고려하기 위한 입력 구성\n",
        "    inputs = vocab(tokenizer(inputs))  # 텍스트 형태의 입력을 모델이 이해 가능한 형태로 변환 (정수형)\n",
        "    inputs = torch.as_tensor(inputs, dtype=torch.int32).unsqueeze(0)  # 모델이 받을 수 있는 데이터 형태로 변환\n",
        "    label = torch.as_tensor(label, dtype=torch.long).unsqueeze(0) # 모델이 받을 수 있는 데이터 형태로 변환\n",
        "\n",
        "    inputs = inputs.to(device)\n",
        "\n",
        "    predicted_label = model(inputs)\n",
        "    predicted_label = predicted_label.detach().cpu()\n",
        "\n",
        "    total_acc += (predicted_label.argmax(1) == label).sum().item()\n",
        "    total_count += label.size(0)\n",
        "\n",
        "    if (i+1) % 1000 == 0:\n",
        "        print(f'평가 진행중.. [{i+1}/{len(test_list)}]')\n",
        "\n",
        "print(f\"학습된 모델의 최종 정확도: {format(total_acc/total_count * 100, '.3f')} %\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9P0Ku062rt0"
      },
      "source": [
        "# **6. 실습 과제**\n",
        "\n",
        "### - 현재 구현된 자연어처리 모델은 매우 단순한 수준으로 구현돼있습니다.\n",
        "\n",
        "### - 현재 구현상의 단점들을 극복하고, **모델의 성능을 향상시킬 수 있는 방법들**을 찾아서 적용시키는 것이 과제입니다.\n",
        "\n",
        "### - 단, 다음 **제한사항**들을 **제외하고**, 그 이외의 방법만을 찾아서 적용해보시기 바랍니다.\n",
        "- ```test_list```를 학습 데이터로 포함시키는 것\n",
        "- ```transformers```패키지 등, 사전학습 언어모델을 사용하는 어떠한 종류의 방법\n",
        "\n",
        "### - 본 실습 자료에 포함된 바, 시도해볼 만한 내용은 다음과 같습니다.\n",
        "- 모델 Hidden size / layer 개수 변경\n",
        "- learning rate 변경 / 학습 step 수 증가\n",
        "\n",
        "### - 본 실습 자료에 포함되지 않았더라도, 성능 개선시킬 수 있는 방법을 찾으신 것이 있다면, 위 제한사항을 제외하고는 모두 적용 가능합니다.\n",
        "\n",
        "### **42% 이상**의 테스트 정확도가 나오도록 구현하는 것이 과제의 목표입니다.\n",
        "### 성능이 목표치에 달하지 못하더라도 괜찮으니 최대한 시도해보시기를 바랍니다.\n",
        "\n",
        "### 구현한 모델, 해당 모델의 학습 코드, 평가 코드가 담긴 **ipynb파일**을 직접 작성하여 제출해주시기 바랍니다.\n",
        "### 본 실습 자료의 **5.Torch를 활용한 자연어처리** 내 모든 셀을 복사해서 사용하시는걸 권장드립니다.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
