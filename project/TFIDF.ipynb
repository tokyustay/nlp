{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AuktXoJRFMtp",
        "outputId": "b4fb960a-5bda-4a23-fe69-17c68130d9b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Keywords:\n",
            "['엔화', '있다', '미국채']\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def extract_top_keywords(paragraph, n=3):\n",
        "    # Tokenize the paragraph into words\n",
        "    words = paragraph.split()\n",
        "\n",
        "    # Create TF-IDF vectorizer\n",
        "    tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "    # Fit and transform the paragraph\n",
        "    tfidf_matrix = tfidf_vectorizer.fit_transform([paragraph])\n",
        "\n",
        "    # Get the feature names (words)\n",
        "    feature_names = tfidf_vectorizer.get_feature_names_out()\n",
        "\n",
        "    # Create a dictionary to store word and corresponding TF-IDF score\n",
        "    word_tfidf_scores = {}\n",
        "    for col in tfidf_matrix.nonzero()[1]:\n",
        "        word = feature_names[col]\n",
        "        tfidf_score = tfidf_matrix[0, col]\n",
        "        word_tfidf_scores[word] = tfidf_score\n",
        "\n",
        "    # Sort the words by their TF-IDF scores\n",
        "    sorted_words_tfidf = sorted(word_tfidf_scores.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    # Extract top keywords\n",
        "    top_keywords = [word for word, _ in sorted_words_tfidf[:n]]\n",
        "\n",
        "    return top_keywords\n",
        "\n",
        "# Test the function\n",
        "paragraph = \"\"\"\n",
        "엔화 약세 지속과 미국 채권금리 강세가 이어지면서 일본 증시에 상장된 미국채 상장지수펀드(ETF)를 매수한 '일학개미'들의 시름이 커져가고 있다.\n",
        "올해 들어 글로벌 증시가 강세를 보인 가운데 엔화 표시 미국채 ETF는 13% 넘는 손실을 기록 중이다.\n",
        "증권가에서는 엔화 약세가 한동안 길어질 수 있다고 내다보고 있다.\n",
        "\"\"\"\n",
        "print(\"Top Keywords:\")\n",
        "print(extract_top_keywords(paragraph))"
      ]
    }
  ]
}